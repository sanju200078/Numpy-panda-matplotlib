# Brain tumor or not
# ===========================
# 1. Mount Google Drive
# ===========================
from google.colab import drive
drive.mount('/content/drive')

# ===========================
# 2. Set dataset paths (CORRECTED)
# ===========================
train_dir = "/content/drive/MyDrive/brain-Tumor-detection/archive/train"
test_dir  = "/content/drive/MyDrive/brain-Tumor-detection/archive/Testing"
model_out = "/content/drive/MyDrive/brain-Tumor-detection/model/brain_tumor_cnn_best.keras"

# ===========================
# 3. Verify folders exist
# ===========================
import os

if not os.path.exists(train_dir):
    raise FileNotFoundError(f"Train folder not found: {train_dir}")

if not os.path.exists(test_dir):
    raise FileNotFoundError(f"Test folder not found: {test_dir}")

print("✅ Dataset folders found:")
print("Train path:", train_dir)
print("Test path:", test_dir)

# ===========================
# 4. Load data with ImageDataGenerator
# ===========================
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)

train_data = datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode="categorical",
    subset="training"
)

val_data = datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode="categorical",
    subset="validation"
)

# ===========================
# 5. Build CNN model
# ===========================
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(train_data.num_classes, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ===========================
# 6. Train the model
# ===========================
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=10
)

# ===========================
# 7. Save trained model to Google Drive
# ===========================
os.makedirs(os.path.dirname(model_out), exist_ok=True)
model.save(model_out)
print(f"✅ Model saved to: {model_out}")

# ===========================
# 8. Optional: Evaluate on test set
# ===========================
test_datagen = ImageDataGenerator(rescale=1.0/255)
test_data = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150,150),
    batch_size=32,
    class_mode="categorical"
)

loss, acc = model.evaluate(test_data)
print(f"Test Accuracy: {acc:.2f}")
--------------------------------------------
output
--------------------------------------
Train path: /content/drive/MyDrive/brain-Tumor-detection/archive/train
Test path: /content/drive/MyDrive/brain-Tumor-detection/archive/Testing
Found 203 images belonging to 2 classes.
Found 50 images belonging to 2 classes.
/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ conv2d (Conv2D)                 │ (None, 148, 148, 32)   │           896 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 74, 74, 32)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 72, 72, 64)     │        18,496 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 36, 36, 64)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 34, 34, 128)    │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_2 (MaxPooling2D)  │ (None, 17, 17, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (None, 36992)          │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │     4,735,104 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 4,828,610 (18.42 MB)
 Trainable params: 4,828,610 (18.42 MB)
 Non-trainable params: 0 (0.00 B)
/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/10
7/7 ━━━━━━━━━━━━━━━━━━━━ 435s 68s/step - accuracy: 0.5817 - loss: 1.7387 - val_accuracy: 0.7400 - val_loss: 0.5511
Epoch 2/10
7/7 ━━━━━━━━━━━━━━━━━━━━ 424s 59s/step - accuracy: 0.6929 - loss: 0.5777 - val_accuracy: 0.7400 - val_loss: 0.5345
Epoch 3/10
7/7 ━━━━━━━━━━━━━━━━━━━━ 419s 59s/step - accuracy: 0.7937 - loss: 0.5181 - val_accuracy: 0.7400 - val_loss: 0.5576
Epoch 4/10
7/7 ━━━━━━━━━━━━━━━━━━━━ 420s 59s/step - accuracy: 0.7978 - loss: 0.4547 - val_accuracy: 0.7400 - val_loss: 0.5441
Epoch 5/10
---model saved-some error commig-so load that model-
----------------------------------------------------------------------------------------------------------
# ===========================
# 1. Load the saved model
# ===========================
from tensorflow.keras.models import load_model
import numpy as np
import os
from tensorflow.keras.preprocessing import image

model_path = "/content/brain_tumor_cnn_best.keras"
model = load_model(model_path)
print("✅ Model loaded successfully")

# ===========================
# 2. Set class labels (must match training)
# ===========================
class_labels = ['No Tumor', 'Tumor']  # Change if your folder names are different

# ===========================
# 3. Loop through Testing1 folder and predict
# ===========================
test_folder = "/content/drive/MyDrive/brain-Tumor-detection/archive/Testing"

for img_name in os.listdir(test_folder):
    img_path = os.path.join(test_folder, img_name)

    # Skip non-image files
    if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
        continue

    # Load and preprocess image
    img = image.load_img(img_path, target_size=(150, 150))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    # Predict
    prediction = model.predict(img_array)
    predicted_class = class_labels[np.argmax(prediction)]

    print(f"{img_name} --> {predicted_class}")

output-
-----------------------------------------------------------------------
Model loaded successfully
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 156ms/step
augmented_144_1.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step
augmented_144_2.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step
augmented_144_3.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step
augmented_145_2.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step
augmented_145_3.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step
augmented_145_4.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step
augmented_146_3.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step
augmented_146_5.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step
augmented_146_4.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 116ms/step
augmented_147_4.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 137ms/step
augmented_147_6.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 114ms/step
augmented_147_5.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 111ms/step
augmented_148_5.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 105ms/step
augmented_148_6.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 115ms/step
augmented_148_7.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 125ms/step
augmented_149_6.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 110ms/step
augmented_149_7.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 114ms/step
augmented_149_8.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 115ms/step
augmented_150_7.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 106ms/step
augmented_150_8.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 142ms/step
augmented_150_9.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 125ms/step
augmented_151_8.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 122ms/step
augmented_151_9.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 110ms/step
augmented_151_10.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 105ms/step
augmented_152_9.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step
augmented_152_10.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step
augmented_153_1.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step
augmented_153_10.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step
augmented_154_1.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step
augmented_154_2.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step
augmented_155_1.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step
augmented_155_2.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step
augmented_155_3.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step
augmented_1_1.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step
augmented_1_3.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step
augmented_1_2.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step
augmented_2_2.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step
augmented_2_3.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step
augmented_2_4.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step
augmented_3_3.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step
augmented_3_4.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step
augmented_3_5.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step
augmented_4_4.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step
augmented_4_5.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step
augmented_4_6.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step
augmented_5_5.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step
augmented_5_6.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step
augmented_5_7.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step
augmented_6_6.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step
augmented_6_7.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step
augmented_6_8.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step
augmented_7_7.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step
augmented_7_8.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step
augmented_7_9.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step
augmented_8_8.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step
augmented_8_9.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step
augmented_8_10.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step
augmented_9_9.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step
augmented_9_10.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step
augmented_10_1.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step
augmented_10_10.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step
augmented_11_1.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step
augmented_11_2.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step
augmented_12_1.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step
augmented_12_2.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step
augmented_12_3.jpg --> Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step
no 923.jpg --> No Tumor
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step
Y258.JPG --> Tumor
